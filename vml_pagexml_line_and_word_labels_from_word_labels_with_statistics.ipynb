{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import shutil\n",
    "from lxml import etree as ET\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from bidi.algorithm import get_display\n",
    "import arabic_reshaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinates(cnt):\n",
    "    coords= str(cnt[0])+','+str(cnt[1])+' '+str(cnt[0]+cnt[2])+','+str(cnt[1])+' '+str(cnt[0]+cnt[2])+','+str(cnt[1]+cnt[3])+' '+str(cnt[0])+','+str(cnt[1]+cnt[3])\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_box(rectList):\n",
    "    arr = []\n",
    "    for rect in rectList:\n",
    "        arr.append((rect[0],rect[1]))\n",
    "        arr.append((rect[0]+rect[2],rect[1]+rect[3]))\n",
    "    (x,y,w,h) = cv2.boundingRect(np.asarray(arr))\n",
    "    return x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_label(labelList):\n",
    "    line_label=''\n",
    "    for label in labelList:\n",
    "        line_label=line_label+' '+label\n",
    "    return line_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_height(h):\n",
    "    if h <= 35:\n",
    "        reduced_h = 5\n",
    "    else:\n",
    "        reduced_h = h - 30\n",
    "    return reduced_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_from_xml(xml_file_path, image_name):\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "    word_bboxes = []\n",
    "    word_labels = []\n",
    "    for page in root.findall('.//image[@src=\"%s\"]'%image_name):\n",
    "        print ('Started to gather the words on '+ image_name)\n",
    "        for zone in page.iter('zone'):           \n",
    "            c = 0\n",
    "            for point in zone.iter('point'):\n",
    "                if c == 0:\n",
    "                    x0 = point.attrib.get('x')\n",
    "                    y0 = point.attrib.get('y')\n",
    "                if c == 1:\n",
    "                    x1 = point.attrib.get('x')\n",
    "                    y1 = point.attrib.get('y')\n",
    "                if c == 2:\n",
    "                    x2 = point.attrib.get('x')\n",
    "                    y2 = point.attrib.get('y')\n",
    "                if c == 3:\n",
    "                    x3 = point.attrib.get('x')\n",
    "                    y3 = point.attrib.get('y')\n",
    "                c = c+1\n",
    "            x = int(x0)\n",
    "            y = int(y0)\n",
    "            w = int(x1)-int(x0)\n",
    "            h = int(y2)-int(y1)          \n",
    "            word_bbox = [x, y, w, h]\n",
    "            id=int(zone.attrib.get('id'))\n",
    "            word_label=None\n",
    "            for segment in root.iter('segment'):\n",
    "                tid=int(segment.attrib.get('id'))\n",
    "                if tid==id:\n",
    "                    word_label= segment[1].text\n",
    "            if word_label is None:\n",
    "                word_label='mislabel'\n",
    "                print ('there is a mismatch label on zone id: ' + str(id))\n",
    "            else:\n",
    "                word_bboxes.append(word_bbox)\n",
    "                word_labels.append(word_label)\n",
    "    print('Gathered '+ str(len(word_labels)) + ' words on ' +image_name)\n",
    "    return word_bboxes, word_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines_from_words(word_bboxes, word_labels):\n",
    "    line_bboxes = []\n",
    "    line_labels = []\n",
    "    sorted_word_bboxes = []\n",
    "    sorted_word_labels = []\n",
    "    # Sort by y coordinate\n",
    "    word_bboxes, word_labels = zip(*sorted(zip(word_bboxes, word_labels), key=lambda p: p[0][1]))\n",
    "    word_bboxes = list(word_bboxes)\n",
    "    word_labels = list(word_labels)\n",
    "    # Bottom of the first rectangle is the baseline\n",
    "    reduced_h = reduce_height(word_bboxes[0][3])\n",
    "    baseline = word_bboxes[0][1] + reduced_h - 1\n",
    "    end_idx = 0\n",
    "    for i in range(len(word_bboxes)):\n",
    "        # Continue iterating until the box whose y coordinate is below the current baseline\n",
    "        if word_bboxes[i][1] > baseline:\n",
    "            # Sort the boxes whose y coordinates are above the current baseline, by their x coordinate, in descending order\n",
    "            word_bboxes[end_idx:i], word_labels[end_idx:i] = zip(*sorted(zip(word_bboxes[end_idx:i], word_labels[end_idx:i]), reverse=True, key=lambda p: p[0][0]))\n",
    "\n",
    "            if len(word_bboxes[end_idx:i])>0:\n",
    "                line_bbox = one_box(word_bboxes[end_idx:i])\n",
    "                line_bboxes.append(line_bbox)\n",
    "                line_label = one_label(word_labels[end_idx:i])\n",
    "                line_labels.append(line_label)\n",
    "                sorted_word_bboxes.append(word_bboxes[end_idx:i])\n",
    "                sorted_word_labels.append(word_labels[end_idx:i])\n",
    "\n",
    "            end_idx = i\n",
    "        # Update the baseline. \n",
    "        # New baseline is the bottom of the box whose y coordinate is below the current baseline\n",
    "        reduced_h = reduce_height(word_bboxes[i][3])\n",
    "        baseline = max(word_bboxes[i][1] + reduced_h - 1, baseline)\n",
    "\n",
    "    # Sort the word bboxes at the final line\n",
    "    word_bboxes[end_idx:i], word_labels[end_idx:i] = zip(*sorted(zip(word_bboxes[end_idx:i], word_labels[end_idx:i]), reverse=True, key=lambda p: p[0][0]))\n",
    "    if len(word_bboxes[end_idx:i])>0:\n",
    "        line_bbox = one_box(word_bboxes[end_idx:i])\n",
    "        line_bboxes.append(line_bbox)\n",
    "        line_label = one_label(word_labels[end_idx:i])\n",
    "        line_labels.append(line_label)\n",
    "        sorted_word_bboxes.append(word_bboxes[end_idx:i])\n",
    "        sorted_word_labels.append(word_labels[end_idx:i])\n",
    "        \n",
    "        return sorted_word_bboxes, sorted_word_labels, line_bboxes, line_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pagexml(xml_folder_path, image_file_path, sorted_word_bboxes, sorted_word_labels, line_bboxes, line_labels):\n",
    "    xmlns = \"http://schema.primaresearch.org/PAGE/gts/pagecontent/2019-07-15\"\n",
    "    xsi =\"http://www.w3.org/2001/XMLSchema-instance\"\n",
    "    schemaLocation = \"http://schema.primaresearch.org/PAGE/gts/pagecontent/2019-07-15 http://schema.primaresearch.org/PAGE/gts/pagecontent/2019-07-15/pagecontent.xsd\"\n",
    "\n",
    "    PcGts = ET.Element(\"{\" + xmlns + \"}PcGts\",\n",
    "                           attrib={\"{\" + xsi + \"}schemaLocation\" : schemaLocation}, \n",
    "                            nsmap={'xsi': xsi, None: xmlns})\n",
    "    PcGts.set(\"pcGtsId\",\"pc-aletheiaexamplepage\")\n",
    "    Metadata = ET.SubElement(PcGts, 'Metadata')\n",
    "    Creator = ET.SubElement(Metadata, 'Creator')\n",
    "    Creator.text='PRImA Research Lab'\n",
    "    Metadata.append(Creator)\n",
    "    Created = ET.SubElement(Metadata, 'Created')\n",
    "    Created.text='2015-07-17T15:27:13' \n",
    "    Metadata.append(Created)\n",
    "    LastChange = ET.SubElement(Metadata, 'LastChange')\n",
    "    LastChange.text='2017-07-14T10:03:33' \n",
    "    Metadata.append(LastChange)\n",
    "    Comments = ET.SubElement(Metadata, 'Comments')\n",
    "    Comments.text='Example Page' \n",
    "    Metadata.append(Comments)\n",
    "    PcGts.append(Metadata)\n",
    "\n",
    "    img = cv2.imread(image_file_path)\n",
    "\n",
    "    rows,cols,_=img.shape\n",
    "    Page=ET.SubElement(PcGts,'Page')\n",
    "    Page.set('imageFilename',image_file_path) \n",
    "    Page.set('imageWidth',str(cols))\n",
    "    Page.set('imageHeight',str(rows))\n",
    "    \n",
    "    textregionid=0\n",
    "    coords= '1,1 '+str(cols-2)+',1 '+str(cols-2)+','+str(rows-2)+' 1,'+str(rows-2)\n",
    "    TextRegion = ET.SubElement(Page, 'TextRegion')   \n",
    "    TextRegion.set('id','r'+str(textregionid))\n",
    "    TextRegion.set('type','paragraph')\n",
    "    Page.append(TextRegion)\n",
    "    Coords = ET.SubElement(TextRegion, 'Coords')        \n",
    "    Coords.set('points',coords)\n",
    "    TextRegion.append(Coords)\n",
    "\n",
    "    textlineid = 0\n",
    "    wordid = 0\n",
    "    for line_bbox in line_bboxes:\n",
    "        tcoords = coordinates(line_bbox)\n",
    "        TextLine = ET.SubElement(TextRegion, 'TextLine')   \n",
    "        TextLine.set('id','l'+str(textlineid))\n",
    "        TextRegion.append(TextLine)\n",
    "\n",
    "        Coords = ET.SubElement(TextLine, 'Coords')        \n",
    "        Coords.set('points',tcoords)\n",
    "        TextLine.append(Coords)\n",
    "\n",
    "        textlinewordid = 0\n",
    "        for word_bbox in sorted_word_bboxes[textlineid]:\n",
    "            wcoords = coordinates(word_bbox)\n",
    "            Word = ET.SubElement(TextLine, 'Word')\n",
    "            Word.set('id','w'+str(wordid))\n",
    "            Coords = ET.SubElement(Word, 'Coords')        \n",
    "            Coords.set('points',wcoords)\n",
    "            TextEquiv = ET.SubElement(Word, 'TextEquiv')\n",
    "            UnicodeTextEquiv = ET.SubElement(TextEquiv, 'Unicode')\n",
    "            UnicodeTextEquiv.text = sorted_word_labels[textlineid][textlinewordid]\n",
    "            TextEquiv.append(UnicodeTextEquiv)\n",
    "            Word.append(TextEquiv)\n",
    "            TextLine.append(Word)\n",
    "            textlinewordid = textlinewordid+1\n",
    "            wordid = wordid + 1\n",
    "\n",
    "        TextEquiv = ET.SubElement(TextLine, 'TextEquiv')\n",
    "        UnicodeTextEquiv = ET.SubElement(TextEquiv, 'Unicode')\n",
    "        UnicodeTextEquiv.text = line_labels[textlineid]\n",
    "        TextEquiv.append(UnicodeTextEquiv)\n",
    "        TextLine.append(TextEquiv)\n",
    "\n",
    "        textlineid = textlineid + 1\n",
    "    \n",
    "    \n",
    "    mydata = ET.tostring(PcGts,pretty_print=True, encoding='utf-8', xml_declaration=True)    \n",
    "    image_name = image_file_path.split('/')[1][:-4]\n",
    "    myfile = open(xml_folder_path+'/'+image_name+'.xml', \"wb\")  \n",
    "    myfile.write(mydata) \n",
    "    myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(image_folder_path, total_sorted_word_labels):\n",
    "    #In total_line_labels every word is accompanied with a space. \n",
    "    #Consider total_sorted_word_labels for counting\n",
    "    print ('STATISTICS OF THE BOOK ' + image_folder_path)\n",
    "\n",
    "    number_of_pages = 0\n",
    "    number_of_lines = 0\n",
    "    number_of_words = 0\n",
    "    avg_number_of_words_per_page = 0\n",
    "    avg_number_of_words_per_line = 0\n",
    "    avg_number_of_words_classes = 0\n",
    "\n",
    "    word_dist_per_class = []\n",
    "    word_dist_per_page = []\n",
    "    word_dist_per_line = []\n",
    "    line_dist_per_page = []\n",
    "\n",
    "    classes, word_dist_per_class = np.unique(flatten(flatten(total_sorted_word_labels)), return_counts=True)\n",
    "    number_of_classes = len(classes)\n",
    "\n",
    "    for page in total_sorted_word_labels:\n",
    "        number_of_pages += 1\n",
    "        line_dist_per_page.extend([len(page)])\n",
    "        word_dist_per_page.extend([len(flatten(page))])\n",
    "        for line in page:\n",
    "            number_of_lines += 1\n",
    "            word_dist_per_line.extend([len(line)])\n",
    "            for word in line:\n",
    "                number_of_words += 1\n",
    "\n",
    "\n",
    "    print('number_of_pages: ',number_of_pages)\n",
    "    print('number_of_lines: ',number_of_lines)\n",
    "    print('number_of_words: ',number_of_words)\n",
    "    print('number_of_classes: ',number_of_classes)\n",
    "    avg_number_of_words_per_page = number_of_words/number_of_pages\n",
    "    avg_number_of_lines_per_page = number_of_lines/number_of_pages\n",
    "    avg_number_of_words_per_line = number_of_words/number_of_lines\n",
    "    avg_number_of_words_classes = number_of_words/number_of_classes\n",
    "    print('avg_number_of_words_per_page: ',avg_number_of_words_per_page)\n",
    "    print('avg_number_of_lines_per_page: ',avg_number_of_lines_per_page)\n",
    "    print('avg_number_of_words_per_line: ',avg_number_of_words_per_line)\n",
    "    print('avg_number_of_words_classes: ',avg_number_of_words_classes)\n",
    "    \n",
    "    if os.path.exists(\"vml_word_line_stats.txt\"s):\n",
    "        os.remove(\"vml_word_line_stats.txt\")\n",
    "    f = open(\"vml_word_line_stats.txt\", \"a\")\n",
    "    f.write('\\n\\n STATISTICS OF THE BOOK ' + image_folder_path + '\\n' )\n",
    "    f.write('number_of_pages: ' + str(number_of_pages) + '\\n')\n",
    "    f.write('number_of_lines: ' + str(number_of_lines) + '\\n')\n",
    "    f.write('number_of_words: ' + str(number_of_words) + '\\n')\n",
    "    f.write('number_of_classes: ' + str(number_of_classes) + '\\n')\n",
    "    f.write('avg_number_of_words_per_page: ' + str(avg_number_of_words_per_page) + '\\n')\n",
    "    f.write('avg_number_of_lines_per_page: ' + str(avg_number_of_lines_per_page) + '\\n')\n",
    "    f.write('avg_number_of_words_per_line: ' + str(avg_number_of_words_per_line) + '\\n')\n",
    "    f.write('avg_number_of_words_classes: ' + str(avg_number_of_words_classes) + '\\n')\n",
    "    f.close()\n",
    "    \n",
    "    #Form the dataframes\n",
    "    book_name_list_for_pages = [image_folder_path] * number_of_pages\n",
    "\n",
    "    word_dist_per_page_df = pd.DataFrame({'book_name': book_name_list_for_pages})\n",
    "    word_dist_per_page_df['number_of_words'] = word_dist_per_page\n",
    "    \n",
    "    line_dist_per_page_df = pd.DataFrame({'book_name': book_name_list_for_pages})\n",
    "    line_dist_per_page_df['number_of_lines'] = line_dist_per_page\n",
    "    \n",
    "    book_name_list_for_lines = [image_folder_path] * number_of_lines\n",
    "    \n",
    "    word_dist_per_line_df = pd.DataFrame({'book_name': book_name_list_for_lines})\n",
    "    word_dist_per_line_df['number_of_words'] = word_dist_per_line\n",
    "    \n",
    "    book_name_list_for_classes = [image_folder_path] * number_of_classes\n",
    "    \n",
    "    word_dist_per_class_df = pd.DataFrame({'book_name': book_name_list_for_classes})\n",
    "    word_dist_per_class_df['number_of_words'] = word_dist_per_class\n",
    "    \n",
    "    return word_dist_per_page_df, word_dist_per_line_df, line_dist_per_page_df, word_dist_per_class_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_paths = ['3249138', '3157556', '3158466', '3426930', '3368132']\n",
    "all_books_word_dist_per_page_df = pd.DataFrame(columns=['book_name','number_of_words'])\n",
    "all_books_word_dist_per_line_df = pd.DataFrame(columns=['book_name','number_of_words'])\n",
    "all_books_line_dist_per_page_df = pd.DataFrame(columns=['book_name','number_of_lines'])\n",
    "all_books_word_dist_per_class_df = pd.DataFrame(columns=['book_name','number_of_words'])\n",
    "all_books_classes_per_book_df = pd.DataFrame(columns=['book_name','number_of_words'])\n",
    "for image_folder_path in image_folder_paths:\n",
    "    print('Started to process the book ', image_folder_path)\n",
    "    xml_file_path = image_folder_path + '/' + image_folder_path + '_word_annotations.xml'\n",
    "    xml_folder_path = image_folder_path + '_word_and_line_annotations'\n",
    "    if os.path.isdir(xml_folder_path):\n",
    "        shutil.rmtree(xml_folder_path)\n",
    "    os.mkdir(xml_folder_path)\n",
    "    total_sorted_word_labels = []\n",
    "    total_line_labels = []\n",
    "    c=0\n",
    "    for image_name_and_ext in os.listdir(image_folder_path):\n",
    "        if image_name_and_ext[-3:] == 'png':\n",
    "            print(image_name_and_ext)\n",
    "            image_name = image_name_and_ext[:-4]\n",
    "\n",
    "            word_bboxes, word_labels = words_from_xml(xml_file_path, image_name)\n",
    "            print ('Started to sort the words on page '+ image_name)\n",
    "            sorted_word_bboxes, sorted_word_labels, line_bboxes, line_labels = lines_from_words(word_bboxes, word_labels)\n",
    "\n",
    "            #Accumulate for total statistics\n",
    "            total_sorted_word_labels.append(sorted_word_labels)\n",
    "            total_line_labels.append(line_labels)\n",
    "\n",
    "            print ('Started to generate pagexml for page '+ image_name)\n",
    "            image_file_path = image_folder_path + '/' + image_name_and_ext\n",
    "            generate_pagexml(xml_folder_path, image_file_path, sorted_word_bboxes, sorted_word_labels, line_bboxes, line_labels)\n",
    "\n",
    "            c=c+1\n",
    "            if c ==2:\n",
    "                break\n",
    "   \n",
    "    word_dist_per_page_df, word_dist_per_line_df, line_dist_per_page_df, word_dist_per_class_df = stats(image_folder_path, total_sorted_word_labels)\n",
    "    all_books_word_dist_per_page_df = pd.concat([all_books_word_dist_per_page_df, word_dist_per_page_df], axis=0)\n",
    "    all_books_word_dist_per_line_df = pd.concat([all_books_word_dist_per_line_df, word_dist_per_line_df], axis=0)\n",
    "    all_books_line_dist_per_page_df = pd.concat([all_books_line_dist_per_page_df, line_dist_per_page_df], axis=0)\n",
    "    all_books_word_dist_per_class_df = pd.concat([all_books_word_dist_per_class_df, word_dist_per_class_df], axis=0)\n",
    "    \n",
    "    total_sorted_word_labels\n",
    "    \n",
    "print ('\\n\\n All the books have been processed.')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x7f138dc3f280>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "reshaped_text = arabic_reshaper.reshape(' '.join(flatten(flatten(total_sorted_word_labels))))\n",
    "bidi_text = get_display(reshaped_text)\n",
    "wordcloud = WordCloud(font_path='arial.ttf',background_color='white', mode='RGB',width=2000,height=1000).generate(bidi_text)\n",
    "wordcloud.to_file(\"wordCloud.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'و ا ا لصو با لقو ل ا لا و ل لا ن حر ف ا لا شبا ع لا يتحر ك و ا يضا لا يثبت ا لا لضر و ة ر على ما في ا لر صى و عن حر ف جر مبنى على ا لسكو ن لا محل له و متعلق بر ض  و نا ضمير مجر و ر متصل مبنى على ا لسكو ن فحمله ا لقر يب مجر و ر بعن و محله ا لبعيد نصب مفعو ل به غير صر يح لر ضى و لو و حر ف عطف مبنى على ا لفتح لا محل له و عن ف جر ر ا يد مبنى على ا لسكو ن لا محل له و لم ضمير مجر و ر متصل مبنى على ا لسكو ن مجر و ر محلا عطف على لمحل ا لقر يب لضمير نا على ا لقو ل بعد م عمل هذ ا ا لز ا يد ا و محله ا لقر يب مجر و ر بعن و محله ا لبعيد نصب عطف على ا لمحل ا لبعيد لذ لك ا لضمير على ا لقو ل بعمل هذ ا ا لز ا يد و ا لقو ل ا لا و ل هو لمختا ر على ما فى ا لر صى من ر ر م و جهه فلير ا جع ا ليه و لما ا ر ا د ا لمص ا لا قتد ا ء با لقر ا ن ا لمجيد و ا لا قتنا ر لحد يث ا لنبى ا لحميد صلى ا لله تعا عليه و سلم كل ا مر د ى با ل لم يبد أ بسم ا لله ا لر ا لر حمن حيم فهو ا قطع و كل ا مر د ى با ل لم يبد ا ء فيه با لحمد لله فهو ا جر م فقا ل بسم ا لله ا لر ا لر حمن حيم ا لبا و حر ف جر للا ستعا نة ا و للملا بسة مبنى على ا لكسر لا محل له من ا لا ا عر ب و متعلق بفعل مقد ر لا فا د ه ا لحصر على ما هو ا لمشهو ر ا و مقد م على ر ء ى ا لبعض من ا غير لجمهو ر على ما في شر ح ا لمشكو ة لعلى ا لقا ى و تفسير ا بن عا د ل و ا لا سم مجر و ر به لفظا و ا لمجر و ر و حد ه ا لى قو ل ا لجمهو ر ا و مع ا لجا ر على قو ل ا لبعص و منصو ب محلا عند ا لمص و تقد ير ا عند ر حمهو ا لخا ة مفعو ل به غير صر يح للفعل ا لمقد ر ا ى با ستعا نة ا سم ا لله تعا ا صنفا و ا صنف با ستعا نة ا سم ا لله تعا و هو فعل مضا ر ع معلو م مر فو ع لفظا بعا مل معنو ى عند ا لجمهو ا و با لهمز ة على قو ل ا لكسا ئى و تحته ا نا عبا ر ة عن ا لمتكلم و هو ضمير مر فو ع متصل مبنى على ا لفتح عند ا لبصير يين لا ن ا لا لف ليست من نفس ا لكلمة و ا نما هى ز ا يد ة جئ بها لبيا ن ا لفتحة لا نه لو لا ا لا لف لسقط ا لفتحة للو قف فيلتبس با ن ا لحر فية ا لمصد ر ية و على ا لسكو ن عند ا لكو فيين لا ن ا لا لف عند هم من نفس ا لكلمة و ا لا و ل هو ا لر ا حج على ما فى ا لر ضى و غير ه مر فو ع محلا لذ لك ا لفعل ا لمقد ر و ا لجملة ا لفعلية لا محل لها ا بتد ا ئية هذ ا عند ا لكو فيين و ا ما عند ا لبصر يين فا لجا ر مع ا لمجر و ر ظر ف مستقر و ضمير ه ا لمنتقل من متعلقة ا لمحذ و ف تحته هو ا ر جع ا لى مبتد ا ء محذ و ف و هو مر فو ع متصل مبنى على ا لفتح ا و على ا لضم مر فو ع محل فا على ا ظر ف ا مستقر و هو معه جملة فعلية ا و مر كب مر فو ع محلا خبر مبت أ محذ و ف مقد ا م و مؤ خر ا ى تضيفى كا ن ا و كا ئن بسم ا لله تعا بسم ا لله تعا تضيفى و ا لجملة ا لا سميه لا محل لها من ا لا ا ب'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(flatten(flatten(total_sorted_word_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.displot(data=all_books_word_dist_per_line_df, x=\"number_of_words\", hue=\"book_name\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.displot(data=all_books_word_dist_per_page_df, x=\"number_of_words\", hue=\"book_name\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.displot(data=all_books_line_dist_per_page_df, x=\"number_of_lines\", hue=\"book_name\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.displot(data=all_books_word_dist_per_class_df, x=\"number_of_words\", hue=\"book_name\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
